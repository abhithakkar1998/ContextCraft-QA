{"chunks": ["A.I. Artificial Intelligence (or simply A.I.) is a 2001 American science fiction drama film directed by Steven Spielberg. The screenplay by Spielberg and screen story by Ian Watson are loosely based on the 1969 short story \"Supertoys Last All Summer Long\" by Brian Aldiss. Set in a futuristic society, the film stars Haley Joel Osment as David, a childlike android uniquely programmed with the ability to love. Jude Law, Frances O'Connor, Brendan Gleeson and William Hurt star in supporting roles.", "Development of A.I. originally began after producer and director Stanley Kubrick acquired the rights to Aldiss's story in the early 1970s. Kubrick hired a series of writers, including Aldiss, Bob Shaw, Ian Watson and Sara Maitland, until the mid-1990s. The film languished in development hell for years, partly because Kubrick felt that computer-generated imagery was not advanced enough to create the David character, which he believed no child actor would convincingly portray.", "In 1995, Kubrick handed A.I. to Spielberg, but the film did not gain momentum until Kubrick died in 1999. Spielberg remained close to Watson's treatment for the screenplay and dedicated the film to Kubrick. A.I. Artificial Intelligence was released on June 29, 2001, by Warner Bros. Pictures in North America. It received generally positive reviews from critics and grossed $235.9 million against a budget of $90\u2013100 million.", "It was also nominated for Best Visual Effects and Best Original Score (for John Williams) at the 74th Academy Awards. In a 2016 BBC poll of 177 critics around the world, A.I. Artificial Intelligence was voted the eighty-third greatest film since 2000. It has since been called one of Spielberg's best works and one of the greatest films of the 21st century, and of all time.", "Active learning is a special case of machine learning in which a learning algorithm can interactively query a human user (or some other information source), to label new data points with the desired outputs. The human user must possess knowledge/expertise in the problem domain, including the ability to consult/research authoritative sources when necessary. In statistics literature, it is sometimes also called optimal experimental design. The information source is also called teacher or oracle.", "There are situations in which unlabeled data is abundant but manual labeling is expensive. In such a scenario, learning algorithms can actively query the user/teacher for labels. This type of iterative supervised learning is called active learning. Since the learner chooses the examples, the number of examples to learn a concept can often be much lower than the number required in normal supervised learning.", "With this approach, there is a risk that the algorithm is overwhelmed by uninformative examples. Recent developments are dedicated to multi-label active learning, hybrid active learning and active learning in a single-pass (on-line) context, combining concepts from the field of machine learning (e.g. conflict and ignorance) with adaptive, incremental learning policies in the field of online machine learning.", "Using active learning allows for faster development of a machine learning algorithm, when comparative updates would require a quantum or super computer. Large-scale active learning projects may benefit from crowdsourcing frameworks such as Amazon Mechanical Turk that include many humans in the active learning loop.", "Adversarial machine learning is the study of the attacks on machine learning algorithms, and of the defenses against such attacks. A survey from May 2020 revealed practitioners' common feeling for better protection of machine learning systems in industrial applications. Machine learning techniques are mostly designed to work on specific problem sets, under the assumption that the training and test data are generated from the same statistical distribution (IID).", "However, this assumption is often dangerously violated in practical high-stake applications, where users may intentionally supply fabricated data that violates the statistical assumption. Most common attacks in adversarial machine learning include evasion attacks, data poisoning attacks, Byzantine attacks and model extraction.", "Affective computing is the study and development of systems and devices that can recognize, interpret, process, and simulate human affects. It is an interdisciplinary field spanning computer science, psychology, and cognitive science.", "While some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion, the more modern branch of computer science originated with Rosalind Picard's 1995 paper entitled \"Affective Computing\" and her 1997 book of the same name published by MIT Press. One of the motivations for the research is the ability to give machines emotional intelligence, including to simulate empathy.", "The machine should interpret the emotional state of humans and adapt its behavior to them, giving an appropriate response to those emotions.", "The AI boom is an ongoing period of rapid progress in the field of artificial intelligence (AI) that started in the late 2010s before gaining international prominence in late 2022 with the public release of ChatGPT. Examples include large language models and generative AI applications developed by OpenAI as well as protein folding prediction led by Google DeepMind. This period is sometimes referred to as an AI spring, to contrast it with previous AI winters.", "AlexNet is a convolutional neural network architecture developed for image classification tasks, notably achieving prominence through its performance in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). It classifies images into 1,000 distinct object categories and is regarded as the first widely recognized application of deep convolutional networks in large-scale visual recognition.", "Developed in 2012 by Alex Krizhevsky in collaboration with Ilya Sutskever and his Ph.D. advisor Geoffrey Hinton at the University of Toronto, the model contains 60 million parameters and 650,000 neurons. The original paper's primary result was that the depth of the model was essential for its high performance, which was computationally expensive, but made feasible due to the utilization of graphics processing units (GPUs) during training.", "The three formed team SuperVision and submitted AlexNet in the ImageNet Large Scale Visual Recognition Challenge on September 30, 2012. The network achieved a top-5 error of 15.3%, more than 10.8 percentage points better than that of the runner-up. The architecture influenced a large number of subsequent work in deep learning, especially in applying neural networks to computer vision.", "Artificial intelligence (AI) has been used in applications throughout industry and academia. In a manner analogous to electricity or computers, AI serves as a general-purpose technology. AI programs are designed to simulate human perception and understanding. These systems are capable of adapting to new information and responding to changing situations.", "Machine learning has been used for various scientific and commercial purposes including language translation, image recognition, decision-making, credit scoring, and e-commerce.", "Artificial general intelligence (AGI)\u2014sometimes called human\u2011level intelligence AI\u2014is a type of artificial intelligence capable of performing the full spectrum of cognitively demanding tasks with proficiency comparable to, or surpassing, that of humans. Some researchers argue that state\u2011of\u2011the\u2011art large language models already exhibit early signs of AGI\u2011level capability, while others maintain that genuine AGI has not yet been achieved.", "AGI is conceptually distinct from artificial superintelligence (ASI), which would outperform the best human abilities across every domain by a wide margin. AGI is considered one of the definitions of strong AI. Unlike artificial narrow intelligence (ANI), whose competence is confined to well\u2011defined tasks, an AGI system can generalise knowledge, transfer skills between domains, and solve novel problems without task\u2011specific reprogramming.", "The concept does not, in principle, require the system to be an autonomous agent; a static model\u2014such as a highly capable large language model\u2014or an embodied robot could both satisfy the definition so long as human\u2011level breadth and proficiency are achieved. Creating AGI is a primary goal of AI research and of companies such as OpenAI, Google, and Meta. A 2020 survey identified 72 active AGI research and development projects across 37 countries.", "The timeline for achieving human\u2011level intelligence AI remains deeply contested. Recent surveys of AI researchers give median forecasts ranging from the early 2030s to mid\u2011century, while still recording significant numbers who expect arrival much sooner\u2014or never at all. Perspectives span four broad camps.", "One group argues AGI could emerge within years or decades; another projects a century or more; a third believes it may never be built; and a vocal minority claims it already exists, pointing to the broad competencies shown by systems such as GPT\u20114 and other large language models. There is debate on the exact definition of AGI and regarding whether modern large language models (LLMs) such as GPT-4 are early forms of AGI. AGI is a common topic in science fiction and futures studies.", "Contention exists over whether AGI represents an existential risk. Many AI experts have stated that mitigating the risk of human extinction posed by AGI should be a global priority. Others find the development of AGI to be in too remote a stage to present such a risk.", "Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.", "Such machines may be called AIs. High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go).", "However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\" Various subfields of AI research are centered around particular goals and the use of particular tools.", "The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics. General intelligence\u2014the ability to complete any task performed by a human on an at least equal level\u2014is among the field's long-term goals.", "To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.", "Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques.", "This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom.", "The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.", "Artificial intelligence art is visual artwork created or enhanced through the use of artificial intelligence (AI) programs. Artists began to create artificial intelligence art in the mid to late 20th century when the discipline was founded. Throughout its history, artificial intelligence art has raised many philosophical concerns related to the human mind, artificial beings, and what can be considered art in a human\u2013AI collaboration.", "Since the 20th century, artists have used AI to create art, some of which has been exhibited in museums and won awards. During the AI boom of the 2020s, text-to-image models such as Midjourney, DALL-E, Stable Diffusion, and FLUX.1 became widely available to the public, allowing users to quickly generate imagery with little effort.", "Commentary about AI art in the 2020s has often focused on issues related to copyright, deception, defamation, and its impact on more traditional artists, including technological unemployment. Opinions have also risen on the possible effect AI generated art might have on creativity.", "In video games, artificial intelligence (AI) is used to generate responsive, adaptive or intelligent behaviors primarily in non-playable characters (NPCs) similar to human-like intelligence. Artificial intelligence has been an integral part of video games since their inception in 1948, first seen in the game Nim. AI in video games is a distinct subfield and differs from academic AI. It serves to improve the game-player experience rather than machine learning or decision making.", "During the golden age of arcade video games the idea of AI opponents was largely popularized in the form of graduated difficulty levels, distinct movement patterns, and in-game events dependent on the player's input. Modern games often implement existing techniques such as pathfinding and decision trees to guide the actions of NPCs. AI is often used in mechanisms which are not immediately visible to the user, such as data mining and procedural-content generation.", "One of the most infamous examples of this NPC technology and gradual difficulty levels can be found in the game Mike Tyson's Punch-Out!! (1987). In general, game AI does not, as might be thought and sometimes is depicted to be the case, mean a realization of an artificial person corresponding to an NPC in the manner of the Turing test or an artificial general intelligence.", "Attention is a machine learning method that determines the relative importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.", "Unlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the forward pass and therefore change with every step of the input. Earlier designs implemented the attention mechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design, namely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention scheme.", "Inspired by ideas about attention in humans, the attention mechanism was developed to address the weaknesses of leveraging information from the hidden layers of recurrent neural networks. Recurrent neural networks favor more recent information contained in words at the end of a sentence, while information earlier in the sentence tends to be attenuated. Attention allows a token equal access to any part of a sentence directly, rather than only through the previous state.", "Bidirectional encoder representations from transformers (BERT) is a language model introduced in October 2018 by researchers at Google. It learns to represent text as a sequence of vectors using self-supervised learning. It uses the encoder-only transformer architecture. BERT dramatically improved the state-of-the-art for large language models. As of 2020, BERT is a ubiquitous baseline in natural language processing (NLP) experiments.", "BERT is trained by masked token prediction and next sentence prediction. As a result of this training process, BERT learns contextual, latent representations of tokens in their context, similar to ELMo and GPT-2. It found applications for many natural language processing tasks, such as coreference resolution and polysemy resolution. It is an evolutionary step over ELMo, and spawned the study of \"BERTology\", which attempts to interpret what is learned by BERT.", "BERT was originally implemented in the English language at two model sizes, BERTBASE (110 million parameters) and BERTLARGE (340 million parameters). Both were trained on the Toronto BookCorpus (800M words) and English Wikipedia  (2,500M words). The weights were released on GitHub. On March 11, 2020, 24 smaller models were released, the smallest being BERTTINY with just 4 million parameters.", "ChatGPT is a generative artificial intelligence chatbot developed by OpenAI and launched in 2022. It is based on large language models (LLMs) such as GPT-4o. ChatGPT can generate human-like conversational responses and enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. It is credited with accelerating the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence (AI).", "Some observers have raised concern about the potential of ChatGPT and similar programs to displace human intelligence, enable plagiarism, or fuel misinformation. ChatGPT is built on OpenAI's proprietary series of generative pre-trained transformer (GPT) models and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. Successive user prompts and replies are considered at each conversation stage as context.", "ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT \"Plus\", \"Pro\", \"Team\", and \"Enterprise\" subscriptions provide additional features such as DALL-E 3 image generation, more capable AI models, and an increased usage limit.", "By January 2023, ChatGPT had become what was then the fastest-growing consumer software application in history, gaining over 102 million users in two months. ChatGPT's release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI's GPT-4. In May 2024, a partnership between Apple Inc. and OpenAI was announced, in which ChatGPT was integrated into the Apple Intelligence feature of Apple operating systems.", "As of April 2025, ChatGPT's website is among the 10 most-visited websites globally.", "Chinchilla is a family of large language models (LLMs) developed by the research team at Google DeepMind, presented in March 2022.", "Chroma or ChromaDB is an open-source vector database tailored to applications with large language models. Its headquarters are in San Francisco. In April 2023, it raised 18 million US dollars as seed funding. ChromaDB has been used in academic studies on artificial intelligence, particularly as part of the tech stack for retrieval-augmented generation.", "Claude is a family of large language models developed by Anthropic. The first model was released in March 2023. The Claude 3 family, released in March 2024, consists of three models: Haiku, optimized for speed; Sonnet, which balances capability and performance; and Opus, designed for complex reasoning tasks.", "These models can process both text and images, with Claude 3 Opus demonstrating enhanced capabilities in areas like mathematics, programming, and logical reasoning compared to previous versions.", "Computer stereo vision is the extraction of 3D information from digital images, such as those obtained by a CCD camera. By comparing information about a scene from two vantage points, 3D information can be extracted by examining the relative positions of objects in the two panels. This is similar to the biological process of stereopsis.", "Computer vision tasks include methods for acquiring, processing, analyzing, and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the form of decisions. \"Understanding\" in this context signifies the transformation of visual images (the input to the retina) into descriptions of the world that make sense to thought processes and can elicit appropriate action.", "This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory. The scientific discipline of computer vision is concerned with the theory behind artificial systems that extract information from images.", "Image data can take many forms, such as video sequences, views from multiple cameras, multi-dimensional data from a 3D scanner, 3D point clouds from LiDaR sensors, or medical scanning devices. The technological discipline of computer vision seeks to apply its theories and models to the construction of computer vision systems.", "Subdisciplines of computer vision include scene reconstruction, object detection, event detection, activity recognition, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modeling, and image restoration.", "Computer Vision Annotation Tool (CVAT) is an open source, web-based image and video annotation tool used for labeling data for computer vision algorithms. Originally developed by Intel, CVAT is designed for use by a professional data annotation team, with a user interface optimized for computer vision annotation tasks. CVAT supports the primary tasks of supervised machine learning: object detection, image classification, and image segmentation.", "CVAT allows users to annotate data for each of these cases. CVAT has many powerful features, including interpolation of shapes between key frames, semi-automatic annotation using deep learning models, shortcuts for most critical actions, a dashboard with a list of annotation projects and tasks, LDAP and basic access authentication, etc. CVAT is written mainly in TypeScript, React, Ant Design, CSS, Python, and Django.", "It is distributed under the MIT License, and its source code is available on GitHub. CVAT team hosts an online version of the data annotation platform at cvat.ai as SaaS.", "Computer vision dazzle, also known as CV dazzle, dazzle makeup, or anti-surveillance makeup, is a type of camouflage used to hamper facial recognition software, inspired by dazzle camouflage used by vehicles such as ships and planes.", "Computer vision syndrome (CVS) is a condition resulting from focusing the eyes on a computer or other display device for protracted, uninterrupted periods of time and the eye's muscles being unable to recover from the constant tension required to maintain focus on a close object.", "A convolutional neural network (CNN) is a type of feedforward neural network that learns features via filter (or kernel) optimization. This type of deep learning network has been applied to process and make predictions from many different types of data including text, images and audio.", "Convolution-based networks are the de-facto standard in deep learning-based approaches to computer vision and image processing, and have only recently been replaced\u2014in some cases\u2014by newer deep learning architectures such as the transformer. Vanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by the regularization that comes from using shared weights over fewer connections.", "For example, for each neuron in the fully-connected layer, 10,000 weights would be required for processing an image sized 100 \u00d7 100 pixels. However, applying cascaded convolution (or cross-correlation) kernels, only 25 weights for each convolutional layer are required to process 5x5-sized tiles. Higher-layer features are extracted from wider context windows, compared to lower-layer features.", "Some applications of CNNs include: \n\nimage and video recognition,\nrecommender systems,\nimage classification,\nimage segmentation,\nmedical image analysis,\nnatural language processing,\nbrain\u2013computer interfaces, and\nfinancial time series.", "CNNs are also known as shift invariant or space invariant artificial neural networks, based on the shared-weight architecture of the convolution kernels or filters that slide along input features and provide translation-equivariant responses known as feature maps. Counter-intuitively, most convolutional neural networks are not invariant to translation, due to the downsampling operation they apply to the input.", "Feedforward neural networks are usually fully connected networks, that is, each neuron in one layer is connected to all neurons in the next layer. The \"full connectivity\" of these networks makes them prone to overfitting data. Typical ways of regularization, or preventing overfitting, include: penalizing parameters during training (such as weight decay) or trimming connectivity (skipped connections, dropout, etc.)", "Robust datasets also increase the probability that CNNs will learn the generalized principles that characterize a given dataset rather than the biases of a poorly-populated set. Convolutional networks were inspired by biological processes in that the connectivity pattern between neurons resembles the organization of the animal visual cortex. Individual cortical neurons respond to stimuli only in a restricted region of the visual field known as the receptive field.", "The receptive fields of different neurons partially overlap such that they cover the entire visual field. CNNs use relatively little pre-processing compared to other image classification algorithms. This means that the network learns to optimize the filters (or kernels) through automated learning, whereas in traditional algorithms these filters are hand-engineered. This simplifies and automates the process, enhancing efficiency and scalability overcoming human-intervention bottlenecks.", "In U.S. education, deeper learning is a set of student educational outcomes including acquisition of robust core academic content, higher-order thinking skills, and learning dispositions. Deeper learning is based on the premise that the nature of work, civic, and everyday life is changing and therefore increasingly requires that formal education provides young people with mastery of skills like analytic reasoning, complex problem solving, and teamwork.", "Deeper learning is associated with a growing movement in U.S. education that places special emphasis on the ability to apply knowledge to real-world circumstances and to solve novel problems. A number of U.S. schools and school districts serving a broad socio-economic spectrum apply deeper learning as an integral component of their instructional approach.", "Deep learning is a subset of machine learning that focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network.", "Methods used can be either supervised, semi-supervised or unsupervised. Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields.", "These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.", "Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.", "\"Deep Learning\" is the fourth episode of the twenty-sixth season of the American animated television series South Park, and the 323rd episode of the series overall. Written and directed by Trey Parker, it premiered on March 8, 2023.", "The episode, which parodies the use of the artificial intelligence chatbot ChatGPT (which is credited as a co-writer for the episode) for text messages, centers upon fourth-grader Stan Marsh, who comes to rely on the software for writing both school essays and romantic texts to his girlfriend Wendy Testaburger, bringing him into conflict with her, his classmates, and school officials.", "Deep Learning Super Sampling (DLSS) is a suite of real-time deep learning image enhancement and upscaling technologies developed by Nvidia that are available in a number of video games. The goal of these technologies is to allow the majority of the graphics pipeline to run at a lower resolution for increased performance, and then infer a higher resolution image from this that approximates the same level of detail as if the image had been rendered at this higher resolution.", "This allows for higher graphical settings and/or frame rates for a given output resolution, depending on user preference. All generations of DLSS are available on all RTX-branded cards from Nvidia in supported titles. However, the Frame Generation feature is only supported on 40 series GPUs or newer and Multi Frame Generation is only available on 50 series GPUs.", "Deep reinforcement learning (deep RL) is a subfield of machine learning that combines reinforcement learning (RL) and deep learning. RL considers the problem of a computational agent learning to make decisions by trial and error. Deep RL incorporates deep learning into the solution, allowing agents to make decisions from unstructured input data without manual engineering of the state space. Deep RL algorithms are able to take in very large inputs (e.g.", "every pixel rendered to the screen in a video game) and decide what actions to perform to optimize an objective (e.g. maximizing the game score). Deep reinforcement learning has been used for a diverse set of applications including but not limited to robotics, video games, natural language processing, computer vision, education, transportation, finance and healthcare.", "Digital image processing is the use of a digital computer to process digital images through an algorithm. As a subcategory or field of digital signal processing, digital image processing has many advantages over analog image processing. It allows a much wider range of algorithms to be applied to the input data and can avoid problems such as the build-up of noise and distortion during processing.", "Since images are defined over two dimensions (perhaps more), digital image processing may be modeled in the form of multidimensional systems.", "The generation and development of digital image processing are mainly affected by three factors: first, the development of computers; second, the development of mathematics (especially the creation and improvement of discrete mathematics theory); and third, the demand for a wide range of applications in environment, agriculture, military, industry and medical science has increased.", "Empirical Methods in Natural Language Processing (EMNLP) is a leading conference in the area of natural language processing and artificial intelligence. Along with the Association for Computational Linguistics (ACL) and the North American Chapter of the Association for Computational Linguistics (NAACL), it is one of the three primary high impact conferences for natural language processing research.", "EMNLP is organized by the ACL special interest group on linguistic data (SIGDAT) and was started in 1996, based on an earlier conference series called Workshop on Very Large Corpora (WVLC). As of 2021, according to Microsoft Academic, EMNLP is the 14th most cited conference in computer science, with a citation count of 332,738, between ICML (#13) and ICLR (#15).", "Face ID is a biometric authentication facial recognition system designed and developed by Apple Inc. for the iPhone and iPad Pro. The system can be used for unlocking a device, making payments, accessing sensitive data, providing detailed facial expression tracking for Animoji, as well as six degrees of freedom (6DOF) head-tracking, eye-tracking, and other features.", "Initially released in November 2017 with the iPhone X, it has since been updated and introduced to all iPhones outside of SE models and all iPad Pro models from 2018 onwards. Users on iOS 18 and newer can choose to lock specific apps, requiring Face ID to access them.", "The Face ID hardware uses a TrueDepth Camera that consists of a sensor with three modules; a laser dot projector that projects a grid of small infrared dots onto a user's face, a module called the flood illuminator that shines infrared light at the face, and an infrared camera that takes an infrared picture of the user, reads the resulting pattern, and generates a 3D facial map. Face ID has sparked a number of debates about security and privacy.", "Apple claims that Face ID is statistically more advanced than Touch ID fingerprint scanning. It exhibits significantly fewer false positives. Multiple security features are in place to limit the risk of the system being bypassed using photos or masks, and only one proof-of-concept attempt using detailed scans has succeeded. Debate continues over the lack of legal protections offered by biometric systems as compared to passcode authentication in the United States.", "Hackers have been able to use combinations of FaceID data and SMS messages to enter various locked information on Apple users iPhones protected by FaceID technology. Privacy advocates have also expressed concern about third-party app developers' access to \"rough maps\" of user facial data, despite rigid requirements by Apple of how developers handle facial data. Privacy concerns also exist regarding the use FaceID data to retrieve other personal information stored on Apple technology.", "Use of FaceID technology and biometric data in criminal cases as been of much debate due to lack of legal regulation. FaceID has been compared to fingerprint and passcode locking mechanisms to evaluate the ethics behind use of FaceID in criminal cases. Finally, infiltration on Apple products has been a concern of the public as twins and close relatives have been successful in fooling the FaceID technology.", "Facial replication into realistic masks has been an infiltration concern, but has thus far been unsuccessful. With the onset of the COVID-19 pandemic, it was noted that Face ID was unable to recognize users wearing face coverings on some devices. Apple responded to criticism by offering faster fallback to passcode input, and the option for Apple Watch users to confirm whether they intended to unlock their iPhone.", "In March 2022, Apple released iOS 15.4 which adds mask-compatible Face ID for iPhone 12 and later devices.", "Facial perception is an individual's understanding and interpretation of the face. Here, perception implies the presence of consciousness and hence excludes automated facial recognition systems. Although facial recognition is found in other species, this article focuses on facial perception in humans. The perception of facial features is an important part of social cognition.", "Information gathered from the face helps people understand each other's identity, what they are thinking and feeling, anticipate their actions, recognize their emotions, build connections, and communicate through body language. Developing facial recognition is a necessary building block for complex societal constructs. Being able to perceive identity, mood, age, sex, and race lets people mold the way we interact with one another, and understand our immediate surroundings.", "Though facial perception is mainly considered to stem from visual intake, studies have shown that even people born blind can learn face perception without vision. Studies have supported the notion of a specialized mechanism for perceiving faces.", "The Face Recognition Grand Challenge (FRGC) was conducted from May 2004 until March 2006 to promote and advance face recognition technology. The FRGC v2 database created in 2005 has had a significant impact on the development of 3D face recognition. Although many other face databases have been created since then, as of 2022, FRGC v2 continued to be used as \"a standard reference database for evaluating 3D face recognition algorithms\".", "A facial recognition system is a technology potentially capable of matching a human face from a digital image or a video frame against a database of faces. Such a system is typically employed to authenticate users through ID verification services, and works by pinpointing and measuring facial features from a given image. Development began on similar systems in the 1960s, beginning as a form of computer application.", "Since their inception, facial recognition systems have seen wider uses in recent times on smartphones and in other forms of technology, such as robotics. Because computerized facial recognition involves the measurement of a human's physiological characteristics, facial recognition systems are categorized as biometrics.", "Although the accuracy of facial recognition systems as a biometric technology is lower than iris recognition, fingerprint image acquisition, palm recognition or voice recognition, it is widely adopted due to its contactless process. Facial recognition systems have been deployed in advanced human\u2013computer interaction, video surveillance, law enforcement, passenger screening, decisions on employment and housing and automatic indexing of images.", "Facial recognition systems are employed throughout the world today by governments and private companies. Their effectiveness varies, and some systems have previously been scrapped because of their ineffectiveness. The use of facial recognition systems has also raised controversy, with claims that the systems violate citizens' privacy, commonly make incorrect identifications, encourage gender norms and racial profiling, and do not protect important biometric data.", "The appearance of synthetic media such as deepfakes has also raised concerns about its security. These claims have led to the ban of facial recognition systems in several cities in the United States. Growing societal concerns led social networking company Meta Platforms to shut down its Facebook facial recognition system in 2021, deleting the face scan data of more than one billion users. The change represented one of the largest shifts in facial recognition usage in the technology's history.", "IBM also stopped offering facial recognition technology due to similar concerns.", "In computer vision and image processing, a feature is a piece of information about the content of an image; typically about whether a certain region of the image has certain properties. Features may be specific structures in the image such as points, edges or objects. Features may also be the result of a general neighborhood operation or feature detection applied to the image.", "Other examples of features are related to motion in image sequences, or to shapes defined in terms of curves or boundaries between different image regions. More broadly a feature is any piece of information that is relevant for solving the computational task related to a certain application. This is the same sense as feature in machine learning and pattern recognition generally, though image processing has a very sophisticated collection of features.", "The feature concept is very general and the choice of features in a particular computer vision system may be highly dependent on the specific problem at hand.", "Feedforward refers to recognition-inference architecture of neural networks. Artificial neural network architectures are based on inputs multiplied by weights to obtain outputs (inputs-to-output): feedforward. Recurrent neural networks, or neural networks with loops allow information from later processing stages to feed back to earlier stages for sequence processing.", "However, at every stage of inference a feedforward multiplication remains the core, essential for backpropagation or backpropagation through time. Thus neural networks cannot contain feedback like negative feedback or positive feedback where the outputs feed back to the very same inputs and modify them, because this forms an infinite loop which is not possible to rewind in time to generate an error signal through backpropagation.", "This issue and nomenclature appear to be a point of confusion between some computer scientists and scientists in other fields studying brain networks.", "The fusiform face area (FFA, meaning spindle-shaped face area) is a part of the human visual system (while also activated in people blind from birth) that is specialized for facial recognition. It is located in the inferior temporal cortex (IT), in the fusiform gyrus (Brodmann area 37).", "Gemini is a family of multimodal large language models developed by Google DeepMind, and the successor to LaMDA and PaLM 2. Comprising Gemini Ultra, Gemini Pro, Gemini Flash, and Gemini Nano, it was announced on December 6, 2023, positioned as a competitor to OpenAI's GPT-4. It powers the chatbot of the same name. In March 2025, Gemini 2.5 Pro Experimental was rated as highly competitive.", "Generative AI pornography or simply AI pornography is a digitally created pornography produced through generative artificial intelligence (AI) technologies. Unlike traditional pornography, which involves real actors and cameras, this content is synthesized entirely by AI algorithms. These algorithms, including Generative adversarial network (GANs) and text-to-image models, generate lifelike images, videos, or animations from textual descriptions or datasets.", "Generative artificial intelligence (Generative AI, GenAI, or GAI) is a subfield of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data. These models learn the underlying patterns and structures of their training data and use them to produce new data based on the input, which often comes in the form of natural language prompts. Generative AI tools have become more common since an \"AI boom\" in the 2020s.", "This boom was made possible by improvements in transformer-based deep neural networks, particularly large language models (LLMs). Major tools include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora. Technology companies developing generative AI include OpenAI, Anthropic, Microsoft, Google, and Baidu.", "Generative AI has raised many ethical questions. It can be used for cybercrime, or to deceive or manipulate people through fake news or deepfakes. Even if used ethically, it may lead to the mass replacement of human jobs. The tools themselves have been criticized as violating intellectual property laws, since they are trained on and emulate copyrighted works of art. Generative AI is used across many industries.", "Examples include software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design.", "A generative pre-trained transformer (GPT) is a type of large language model (LLM) and a prominent framework for generative artificial intelligence. It is an artificial neural network that is used in natural language processing by machines. It is based on the transformer deep learning architecture, pre-trained on large data sets of unlabeled text, and able to generate novel human-like content. As of 2023, most LLMs had these characteristics and are sometimes referred to broadly as GPTs.", "The first GPT was introduced in 2018 by OpenAI. OpenAI has released significant GPT foundation models that have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these was significantly more capable than the previous, due to increased size (number of trainable parameters) and training. The most recent of these, GPT-4o, was released in May 2024.", "Such models have been the basis for their more task-specific GPT systems, including models fine-tuned for instruction following\u2014which in turn power the ChatGPT chatbot service. The term \"GPT\" is also used in the names and descriptions of such models developed by others. For example, other GPT foundation models include a series of models created by EleutherAI, and seven models created by Cerebras in 2023.", "Companies in different industries have developed task-specific GPTs in their respective fields, such as Salesforce's \"EinsteinGPT\" (for CRM) and Bloomberg's \"BloombergGPT\" (for finance).", "Gradient domain image processing, also called Poisson image editing, is a type of digital image processing that operates directly on the differences between neighboring pixels, rather than on the pixel values. Mathematically, an image gradient represents the derivative of an image, so the goal of gradient domain processing is to construct a new image by integrating the gradient, which requires solving Poisson's equation.", "Graph neural networks (GNN) are specialized artificial neural networks that are designed for tasks whose inputs are graphs. One prominent example is molecular drug design. Each input sample is a graph representation of a molecule, where atoms form the nodes and chemical bonds between atoms form the edges. In addition to the graph representation, the input also includes known chemical properties for each of the atoms.", "Dataset samples may thus differ in length, reflecting the varying numbers of atoms in molecules, and the varying number of bonds between them. The task is to predict the efficacy of a given molecule for a specific medical application, like eliminating E. coli bacteria. The key design element of GNNs is the use of pairwise message passing, such that graph nodes iteratively update their representations by exchanging information with their neighbors.", "Several GNN architectures have been proposed, which implement different flavors of message passing,  started by recursive or convolutional constructive approaches. As of 2022, it is an open question whether it is possible to define GNN architectures \"going beyond\" message passing, or instead every GNN can be built on message passing over suitably defined graphs.", "In the more general subject of \"geometric deep learning\", certain existing neural network architectures can be interpreted as GNNs operating on suitably defined graphs. A convolutional neural network layer, in the context of computer vision, can be considered a GNN applied to graphs whose nodes are pixels and only adjacent pixels are connected by edges in the graph.", "A transformer layer, in natural language processing, can be considered a GNN applied to complete graphs whose nodes are words or tokens in a passage of natural language text. Relevant application domains for GNNs include natural language processing, social networks, citation networks, molecular biology, chemistry, physics and NP-hard combinatorial optimization problems.", "Open source libraries implementing GNNs include PyTorch Geometric (PyTorch), TensorFlow GNN (TensorFlow), Deep Graph Library (framework agnostic), jraph (Google JAX), and GraphNeuralNetworks.jl/GeometricFlux.jl (Julia, Flux).", "In the field of artificial intelligence (AI), a hallucination or artificial hallucination (also called bullshitting, confabulation or delusion) is a response generated by AI that contains false or misleading information presented as fact. This term draws a loose analogy with human psychology, where hallucination typically involves false percepts.", "However, there is a key difference: AI hallucination is associated with erroneously constructed responses (confabulation), rather than perceptual experiences. For example, a chatbot powered by large language models (LLMs), like ChatGPT, may embed plausible-sounding random falsehoods within its generated content. Researchers have recognized this issue, and by 2023, analysts estimated that chatbots hallucinate as much as 27% of the time, with factual errors present in 46% of generated texts.", "Detecting and mitigating these hallucinations pose significant challenges for practical deployment and reliability of LLMs in real-world scenarios. Some people believe the specific term \"AI hallucination\" unreasonably anthropomorphizes computers.", "The history of artificial intelligence (AI) began in antiquity, with myths, stories, and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen. The study of logic and formal reasoning from antiquity to the present led directly to the invention of the programmable digital computer in the 1940s, a machine based on abstract mathematical reasoning.", "This device and the ideas behind it inspired scientists to begin discussing the possibility of building an electronic brain. The field of AI research was founded at a workshop held on the campus of Dartmouth College in 1956. Attendees of the workshop became the leaders of AI research for decades. Many of them predicted that machines as intelligent as humans would exist within a generation. The U.S. government provided millions of dollars with the hope of making this vision come true.", "Eventually, it became obvious that researchers had grossly underestimated the difficulty of this feat. In 1974, criticism from James Lighthill and pressure from the U.S.A. Congress led the U.S. and British Governments to stop funding undirected research into artificial intelligence. Seven years later, a visionary initiative by the Japanese Government and the success of expert systems  reinvigorated investment in AI, and by the late 1980s, the industry had grown into a billion-dollar enterprise.", "However, investors' enthusiasm waned in the 1990s, and the field was criticized in the press and avoided by industry (a period known as an \"AI winter\"). Nevertheless, research and funding continued to grow under other names. In the early 2000s, machine learning was applied to a wide range of problems in academia and industry. The success was due to the availability of powerful computer hardware, the collection of immense data sets, and the application of solid mathematical methods.", "Soon after, deep learning proved to be a breakthrough technology, eclipsing all other methods. The transformer architecture debuted in 2017 and was used to produce impressive generative AI applications, amongst other use cases. Investment in AI boomed in the 2020s. The recent AI boom, initiated by the development of transformer architecture, led to the rapid scaling and public releases of large language models (LLMs) like ChatGPT.", "These models exhibit human-like traits of knowledge, attention, and creativity, and have been integrated into various sectors, fueling exponential investment in AI. However, concerns about the potential risks and ethical implications of advanced AI have also emerged, prompting debate about the future of AI and its impact on society.", "Artificial neural networks (ANNs) are models created using machine learning to perform a number of tasks. Their creation was inspired by biological neural circuitry. While some of the computational implementations ANNs relate to earlier discoveries in mathematics, the first implementation of ANNs was by psychologist Frank Rosenblatt, who developed the perceptron. Little research was conducted on ANNs in the 1970s and 1980s, with the AAAI calling this period an \"AI winter\".", "Later, advances in hardware and the development of the backpropagation algorithm, as well as recurrent neural networks and convolutional neural networks, renewed interest in ANNs. The 2010s saw the development of a deep neural network (i.e., one with many layers) called AlexNet. It greatly outperformed other image recognition models, and is thought to have launched the ongoing AI spring, and further increasing interest in deep learning.", "The transformer architecture was first described in 2017 as a method to teach ANNs grammatical dependencies in language, and is the predominant architecture used by large language models such as GPT-4. Diffusion models were first described in 2015, and became the basis of image generation models such as DALL-E in the 2020s.", "The history of natural language processing describes the advances of natural language processing. There is some overlap with the history of machine translation, the history of speech recognition, and the history of artificial intelligence.", "In the field of computer vision, any two images of the same planar surface in space are related by a homography (assuming a pinhole camera model). This has many practical applications, such as image rectification, image registration, or camera motion\u2014rotation and translation\u2014between two images.", "Once camera resectioning has been done from an estimated homography matrix, this information may be used for navigation, or to insert models of 3D objects into an image or video, so that they are rendered with the correct perspective and appear to have been part of the original scene (see Augmented reality).", "An image is a visual representation. An image can be two-dimensional, such as a drawing, painting, or photograph, or three-dimensional, such as a carving or sculpture. Images may be displayed through other media, including a projection on a surface, activation of electronic signals, or digital displays; they can also be reproduced through mechanical means, such as photography, printmaking, or photocopying. Images can also be animated through digital or physical processes.", "In the context of signal processing, an image is a distributed amplitude of color(s). In optics, the term image (or optical image) refers specifically to the reproduction of an object formed by light waves coming from the object. A volatile image exists or is perceived only for a short period. This may be a reflection of an object by a mirror, a projection of a camera obscura, or a scene displayed on a cathode-ray tube.", "A fixed image, also called a hard copy, is one that has been recorded on a material object, such as paper or textile. A mental image exists in an individual's mind as something one remembers or imagines. The subject of an image does not need to be real; it may be an abstract concept such as a graph or function or an imaginary entity.", "For a mental image to be understood outside of an individual's mind, however, there must be a way of conveying that mental image through the words or visual productions of the subject.", "An image processor, also known as an image processing engine, image processing unit (IPU), or image signal processor (ISP), is a type of media processor or specialized digital signal processor (DSP) used for image processing, in digital cameras or other devices. Image processors often employ parallel computing even with SIMD or MIMD technologies to increase speed and efficiency. The digital image processing engine can perform a range of tasks.", "To increase the system integration on embedded devices, often it is a system on a chip with multi-core processor architecture.", "In image processing, a kernel, convolution matrix, or mask is a small matrix used for blurring, sharpening, embossing, edge detection, and more. This is accomplished by doing a convolution between the kernel and an image. Or more simply, when each pixel in the output image is a function of the nearby pixels (including itself) in the input image, the kernel is that function.", "LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.", "A language model is a model of natural language. Language models are useful for a variety of tasks, including speech recognition, machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.", "Large language models (LLMs), currently their most advanced form, are predominantly based on transformers trained on larger datasets (frequently using words scraped from the public internet). They have superseded recurrent neural network-based models, which had previously superseded the purely statistical models, such as word n-gram language model.", "A large language model (LLM) is a type of machine learning model designed for natural language processing tasks such as language generation. LLMs are language models with many parameters, and are trained with self-supervised learning on a vast amount of text. The largest and most capable LLMs are generative pretrained transformers (GPTs). Modern models can be fine-tuned for specific tasks or guided by prompt engineering.", "These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained in.", "Large language models have been used by officials and politicians in a wide variety of ways.", "These datasets are used in machine learning (ML) research and have been cited in peer-reviewed academic journals. Datasets are an integral part of the field of machine learning. Major advances in this field can result from advances in learning algorithms (such as deep learning), computer hardware, and, less-intuitively, the availability of high-quality training datasets.", "High-quality labeled training datasets for supervised and semi-supervised machine learning algorithms are usually difficult and expensive to produce because of the large amount of time needed to label the data. Although they do not need to be labeled, high-quality datasets for unsupervised learning can also be difficult and costly to produce. Many organizations, including governments, publish and share their datasets.", "The datasets are classified, based on the licenses, as Open data and Non-Open data. The datasets from various governmental-bodies are presented in List of open government data sites. The datasets are ported on open data portals. They are made available for searching, depositing and accessing through interfaces like Open API. The datasets are made available as various sorted types and subtypes.", "This is a list of datasets for machine learning research. It is part of the list of datasets for machine-learning research. These datasets consist primarily of images or videos for tasks such as object detection, facial recognition, and multi-label classification.", "A large language model (LLM) is a type of machine learning model designed for natural language processing tasks such as language generation. LLMs are language models with many parameters, and are trained with self-supervised learning on a vast amount of text. This page lists notable large language models.", "Llama (Large Language Model Meta AI, formerly stylized as LLaMA) is a family of large language models (LLMs) released by Meta AI starting in February 2023. The latest version is Llama 4, released in April 2025. Llama models come in different sizes, ranging from 1 billion to 2 trillion parameters. Initially only a foundation model, starting with Llama 2, Meta AI released instruction fine-tuned versions alongside foundation models.", "Model weights for the first version of Llama were only available to researchers on a case-by-case basis, under a non-commercial license. Unauthorized copies of the first model were shared via BitTorrent. Subsequent versions of Llama were made accessible outside academia and released under licenses that permitted some commercial use. Alongside the release of Llama 3, Meta added virtual assistant features to Facebook and WhatsApp in select regions, and a standalone website.", "Both services use a Llama 3 model.", "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.", "ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics. Statistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning.", "From a theoretical viewpoint, probably approximately correct learning provides a framework for describing machine learning.", "Microscope image processing is a broad term that covers the use of digital image processing techniques to process, analyze and present images obtained from a microscope. Such processing is now commonplace in a number of diverse fields such as medicine, biological research, cancer research, drug testing, metallurgy, etc. A number of manufacturers of microscopes now specifically design in features that allow the microscopes to interface to an image processing system.", "Moving object detection is a technique used in computer vision and image processing. Multiple consecutive frames from a video are compared by various methods to determine if any moving object is detected. Moving objects detection has been used for wide range of applications like video surveillance, activity recognition, road condition monitoring, airport safety, monitoring of protection along marine border, etc.", "Music and artificial intelligence (music and AI) is the development of music software programs which use AI to generate music. As with applications in other fields, AI in music also simulates mental tasks. A prominent feature is the capability of an AI algorithm to learn based on past data, such as in computer accompaniment technology, wherein the AI is capable of listening to a human performer and performing accompaniment.", "Artificial intelligence also drives interactive composition technology, wherein a computer composes music in response to a live performance. There are other AI applications in music that cover not only music composition, production, and performance but also how music is marketed and consumed. Several music player programs have also been developed to use voice recognition and natural language processing technology for music voice control.", "Current research includes the application of AI in music composition, performance, theory and digital sound processing. Composers/artists like Jennifer Walshe or Holly Herndon have been exploring aspects of music AI for years in their performances and musical works. Another original approach of humans \u201cimitating AI\u201d can be found in the 43-hour sound installation String Quartet(s) by Georges Lentz.", "20th century art historian Erwin Panofsky proposed that in all art, there existed three levels of meaning: primary meaning, or the natural subject; secondary meaning, or the conventional subject; and tertiary meaning, the intrinsic content of the subject. AI music explores the foremost of these, creating music without the \"intention\" which is usually behind it, leaving composers who listen to machine-generated pieces feeling unsettled by the lack of apparent meaning.", "Natural-language user interface (LUI or NLUI) is a type of computer human interface where linguistic phenomena such as verbs, phrases and clauses act as UI controls for creating, selecting and modifying data in software applications. In interface design, natural-language interfaces are sought after for their speed and ease of use, but most suffer the challenges to understanding wide varieties of ambiguous input.", "Natural-language interfaces are an active area of study in the field of natural-language processing and computational linguistics. An intuitive general natural-language interface is one of the active goals of the Semantic Web. Text interfaces are \"natural\" to varying degrees. Many formal (un-natural) programming languages incorporate idioms of natural human language. Likewise, a traditional keyword search engine could be described as a \"shallow\" natural-language user interface.", "In neuropsychology, linguistics, and philosophy of language, a natural language or ordinary language is any language that occurs naturally in a human community by a process of use, repetition, and change. It can take different forms, typically either a spoken language or a sign language. Natural languages are distinguished from constructed and formal languages such as those used to program computers or to study logic.", "Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics.", "Major tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation.", "The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It supports classification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.", "NLTK includes graphical demonstrations and sample data. It is accompanied by a book that explains the underlying concepts behind the language processing tasks supported by the toolkit, plus a cookbook. NLTK is intended to support research and teaching in NLP or closely related areas, including empirical linguistics, cognitive science, artificial intelligence, information retrieval, and machine learning.", "NLTK has been used successfully as a teaching tool, as an individual study tool, and as a platform for prototyping and building research systems. There are 32 universities in the US and 25 countries using NLTK in their courses.", "NebulaGraph is a free software distributed graph database built for super large-scale graphs with milliseconds of latency. NebulaGraph adopts the Apache 2.0 license and  also  comes with a wide range of data visualization tools.", "A neural network is a group of interconnected units called neurons that send signals to one another. Neurons can be either biological cells or mathematical models. While individual neurons are simple, many of them together in a network can perform complex tasks. There are two main types of neural networks. In neuroscience, a biological neural network is a physical structure found in brains and complex nervous systems \u2013 a population of nerve cells connected by synapses.", "In machine learning, an artificial neural network is a mathematical model used to approximate nonlinear functions. Artificial neural networks are used to solve artificial intelligence problems.", "A neural network, also called a neuronal network, is an interconnected population of neurons (typically containing multiple neural circuits). Biological neural networks are studied to understand the organization and functioning of nervous systems. Closely related are artificial neural networks, machine learning models inspired by biological neural networks.", "They consist of artificial neurons, which are mathematical functions that are designed to be analogous to the mechanisms used by neural circuits.", "In machine learning, a neural network (also artificial neural network or neural net, abbreviated ANN or NN) is a computational model inspired by the structure and functions of biological neural networks. A neural network consists of connected units or nodes called artificial neurons, which loosely model the neurons in the brain. Artificial neuron models that mimic biological neurons more closely have also been recently investigated and shown to significantly improve performance.", "These are connected by edges, which model the synapses in the brain. Each artificial neuron receives signals from connected neurons, then processes them and sends a signal to other connected neurons. The \"signal\" is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs, called the activation function. The strength of the signal at each connection is determined by a weight, which adjusts during the learning process.", "Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly passing through multiple intermediate layers (hidden layers). A network is typically called a deep neural network if it has at least two hidden layers.", "Artificial neural networks are used for various tasks, including predictive modeling, adaptive control, and solving problems in artificial intelligence. They can learn from experience, and can derive conclusions from a complex and seemingly unrelated set of information.", "In image processing, normalization is a process that changes the range of pixel intensity values. Applications include photographs with poor contrast due to glare, for example. Normalization is sometimes called contrast stretching or histogram stretching. In more general fields of data processing, such as digital signal processing, it is referred to as dynamic range expansion.", "The purpose of dynamic range expansion in the various applications is usually to bring the image, or other type of signal, into a range that is more familiar or normal to the senses, hence the term normalization. Often, the motivation is to achieve consistency in dynamic range for a set of data, signals, or images to avoid mental distraction or fatigue. For example, a newspaper will strive to make all of the images in an issue share a similar range of grayscale.", "Normalization transforms an n-dimensional grayscale image \n\n  \n    \n      \n        I\n        :\n        {\n        \n          X\n        \n        \u2286\n        \n          \n            R\n          \n          \n            n\n          \n        \n        }\n        \u2192\n        {\n        \n          Min\n        \n        ,\n        . .", ",\n        \n          Max\n        \n        }\n      \n    \n    {\\displaystyle I:\\{\\mathbb {X} \\subseteq \\mathbb {R} ^{n}\\}\\rightarrow \\{{\\text{Min}},..,{\\text{Max}}\\}}\n  \n\nwith intensity values in the range \n  \n    \n      \n        (\n        \n          Min\n        \n        ,\n        \n          Max\n        \n        )\n      \n    \n    {\\displaystyle ({\\text{Min}},{\\text{Max}})}\n  \n, into a new image \n\n  \n    \n      \n        \n          I\n          \n            N\n          \n        \n        :\n        {\n        \n          X\n        \n        \u2286\n        \n          \n            R\n          \n          \n            n\n          \n        \n        }\n        \u2192\n        {\n        \n          newMin\n        \n        ,\n        .", ". ,\n        \n          newMax\n        \n        }\n      \n    \n    {\\displaystyle I_{N}:\\{\\mathbb {X} \\subseteq \\mathbb {R} ^{n}\\}\\rightarrow \\{{\\text{newMin}},..,{\\text{newMax}}\\}}\n  \n \nwith intensity values in the range \n  \n    \n      \n        (\n        \n          newMin\n        \n        ,\n        \n          newMax\n        \n        )\n      \n    \n    {\\displaystyle ({\\text{newMin}},{\\text{newMax}})}\n  \n.", "The linear normalization of a grayscale digital image is performed according to the formula\n\n  \n    \n      \n        \n          I\n          \n            N\n          \n        \n        =\n        (\n        I\n        \u2212\n        \n          Min\n        \n        )\n        \n          \n            \n              \n                newMax\n              \n              \u2212\n              \n                newMin\n              \n            \n            \n              \n                Max\n              \n              \u2212\n              \n                Min\n              \n            \n          \n        \n        +\n        \n          newMin\n        \n      \n    \n    {\\displaystyle I_{N}=(I-{\\text{Min}}){\\frac {{\\text{newMax}}-{\\text{newMin}}}{{\\text{Max}}-{\\text{Min}}}}+{\\text{newMin}}}\n  \n\nFor example, if the intensity range of the image is 50 to 180 and the desired range is 0 to 255 the process entails subtracting 50 from each of pixel intensity, making the range 0 to 130.", "Then each pixel intensity is multiplied by 255/130, making the range 0 to 255. Normalization might also be non linear, this happens when there isn't a linear relationship between \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  \n and \n  \n    \n      \n        \n          I\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle I_{N}}\n  \n.", "An example of non-linear normalization is when the normalization follows a sigmoid function, in that case, the normalized image is computed according to the formula\n\n  \n    \n      \n        \n          I\n          \n            N\n          \n        \n        =\n        (\n        \n          newMax\n        \n        \u2212\n        \n          newMin\n        \n        )\n        \n          \n            1\n            \n              1\n              +\n              \n                e\n                \n                  \u2212\n                  \n                    \n                      \n                        I\n                        \u2212\n                        \u03b2\n                      \n                      \u03b1\n                    \n                  \n                \n              \n            \n          \n        \n        +\n        \n          newMin\n        \n      \n    \n    {\\displaystyle I_{N}=({\\text{newMax}}-{\\text{newMin}}){\\frac {1}{1+e^{-{\\frac {I-\\beta }{\\alpha }}}}}+{\\text{newMin}}}\n  \n\nWhere \n  \n    \n      \n        \u03b1\n      \n    \n    {\\displaystyle \\alpha }\n  \n defines the width of the input intensity range, and \n  \n    \n      \n        \u03b2\n      \n    \n    {\\displaystyle \\beta }\n  \n defines the intensity around which the range is centered.", "Auto-normalization in image processing software typically normalizes to the full dynamic range of the number system specified in the image file format.", "Object detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class (such as humans, buildings, or cars) in digital images and videos. Well-researched domains of object detection include face detection and pedestrian detection. Object detection has applications in many areas of computer vision, including image retrieval and video surveillance.", "OpenAI o1 is a reflective generative pre-trained transformer (GPT). A preview of o1 was released by OpenAI on September 12, 2024. o1 spends time \"thinking\" before it answers, making it better at complex reasoning tasks, science and programming than GPT-4o. The full version was released to ChatGPT users on December 5, 2024.", "The following outline is provided as an overview of and topical guide to natural-language processing:\nnatural-language processing \u2013 computer activity in which computers are entailed to analyze, understand, alter, or generate natural language. This includes the automation of any or all linguistic forms, activities, or methods of communication, such as conversation, correspondence, reading, written composition, dictation, publishing, translation, lip reading, and so on.", "Natural-language processing is also the name of the branch of computer science, artificial intelligence, and linguistics concerned with enabling computers to engage in communication using natural language(s) in all forms, including but not limited to speech, print, writing, and signing.", "Object recognition \u2013 technology in the field of computer vision for finding and identifying objects in an image or video sequence. Humans recognize a multitude of objects in images with little effort, despite the fact that the image of the objects may vary somewhat in different view points, in many different sizes and scales or even when they are translated or rotated. Objects can even be recognized when they are partially obstructed from view.", "This task is still a challenge for computer vision systems. Many approaches to the task have been implemented over multiple decades.", "Pareidolia (; also US: ) is the tendency for perception to impose a meaningful interpretation on a nebulous stimulus, usually visual, so that one detects an object, pattern, or meaning where there is none. Pareidolia is a specific but common type of apophenia (the tendency to perceive meaningful connections between unrelated things or ideas).", "Common examples include perceived images of animals, faces, or objects in cloud formations; seeing faces in inanimate objects; or lunar pareidolia like the Man in the Moon or the Moon rabbit. The concept of pareidolia may extend to include hidden messages in recorded music played in reverse or at higher- or lower-than-normal speeds, and hearing voices (mainly indistinct) or music in random noise, such as that produced by air conditioners or by fans.", "Face pareidolia has also been demonstrated in rhesus macaques.", "Physics-informed neural networks (PINNs), also referred to as Theory-Trained Neural Networks (TTNs), are a type of universal function approximators that can embed the knowledge of any physical laws that govern a given data-set in the learning process, and can be described by partial differential equations (PDEs). Low data availability for some biological and engineering problems limit the robustness of conventional machine learning models used for these applications.", "The prior knowledge of general physical laws acts in the training of neural networks (NNs) as a regularization agent that limits the space of admissible solutions, increasing the generalizability of the function approximation. This way, embedding this prior information into a neural network results in enhancing the information content of the available data, facilitating the learning algorithm to capture the right solution and to generalize well even with a low amount of training examples.", "In the fields of computing and computer vision, pose (or spatial pose) represents the position and the orientation of an object, each usually in three dimensions. Poses are often stored internally as transformation matrices. The term \u201cpose\u201d is largely synonymous with the term \u201ctransform\u201d, but a transform may often include scale, whereas pose does not. In computer vision, the pose of an object is often estimated from camera input by the process of pose estimation.", "This information can then be used, for example, to allow a robot to manipulate an object or to avoid moving into the object based on its perceived position and orientation in the environment. Other applications include skeletal action recognition.", "Prompt engineering is the process of structuring or crafting an instruction in order to produce the best possible output from a generative artificial intelligence (AI) model. A prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text language model can be a query, a command, or a longer statement including context, instructions, and conversation history.", "Prompt engineering may involve phrasing a query, specifying a style, choice of words and grammar, providing relevant context, or describing a character for the AI to mimic. When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\".", "Prompting a text-to-image model may involve adding, removing, emphasizing, and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.", "Prosopagnosia, also known as face blindness, is a cognitive disorder of face perception in which the ability to recognize familiar faces, including one's own face (self-recognition), is impaired, while other aspects of visual processing (e.g., object discrimination) and intellectual functioning (e.g., decision-making) remain intact.", "The term originally referred to a condition following acute brain damage (acquired prosopagnosia), but a congenital or developmental form of the disorder also exists, with a prevalence of 2.5%.", "Pyramid, or pyramid representation, is a type of multi-scale signal representation developed by the computer vision, image processing and signal processing communities, in which a signal or an image is subject to repeated smoothing and subsampling. Pyramid representation is a predecessor to scale-space representation and multiresolution analysis.", "Q-learning is a reinforcement learning algorithm that trains an agent to assign values to its possible actions based on its current state, without requiring a model of the environment (model-free). It can handle problems with stochastic transitions and rewards without requiring adaptations. For example, in a grid maze, an agent learns to reach an exit worth 10 points.", "At a junction, Q-learning might assign a higher value to moving right than left if right gets to the exit faster, improving this choice by trying both directions over time. For any finite Markov decision process, Q-learning finds an optimal policy in the sense of maximizing the expected value of the total reward over any and all successive steps, starting from the current state.", "Q-learning can identify an optimal action-selection policy for any given finite Markov decision process, given infinite exploration time and a partly random policy. \"Q\" refers to the function that the algorithm computes: the expected reward\u2014that is, the quality\u2014of an action taken in a given state.", "Quantum machine learning is the integration of quantum algorithms within machine learning programs. The most common use of the term refers to machine learning algorithms for the analysis of classical data executed on a quantum computer, i.e. quantum-enhanced machine learning.", "While machine learning algorithms are used to compute immense quantities of data, quantum machine learning utilizes qubits and quantum operations or specialized quantum systems to improve computational speed and data storage done by algorithms in a program. This includes hybrid methods that involve both classical and quantum processing, where computationally difficult subroutines are outsourced to a quantum device.", "These routines can be more complex in nature and executed faster on a quantum computer. Furthermore, quantum algorithms can be used to analyze quantum states instead of classical data. Beyond quantum computing, the term \"quantum machine learning\" is also associated with classical machine learning methods applied to data generated from quantum experiments (i.e. machine learning of quantum systems), such as learning the phase transitions of a quantum system or creating new quantum experiments.", "Quantum machine learning also extends to a branch of research that explores methodological and structural similarities between certain physical systems and learning systems, in particular neural networks. For example, some mathematical and numerical techniques from quantum physics are applicable to classical deep learning and vice versa.", "Furthermore, researchers investigate more abstract notions of learning theory with respect to quantum information, sometimes referred to as \"quantum learning theory\".", "Quantum natural language processing (QNLP) is the application of quantum computing to natural language processing (NLP). It computes word embeddings as parameterised quantum circuits that can solve NLP tasks faster than any classical computer. It is inspired by categorical quantum mechanics and the DisCoCat framework, making use of string diagrams to translate from grammatical structure to quantum processes.", "Reasoning language models are artificial intelligence systems that combine natural language processing with structured reasoning capabilities. These models are usually constructed by prompting, supervised finetuning (SFT), and reinforcement learning (RL) initialized with pretrained language models.", "", "In the context of artificial neural networks, the rectifier or ReLU (rectified linear unit) activation function is an activation function defined as the non-negative part of its argument, i.e., the ramp function:\n\n  \n    \n      \n        ReLU\n        \u2061\n        (\n        x\n        )\n        =\n        \n          x\n          \n            +\n          \n        \n        =\n        max\n        (\n        0\n        ,\n        x\n        )\n        =\n        \n          \n            \n              x\n              +\n              \n                |\n              \n              x\n              \n                |\n              \n            \n            2\n          \n        \n        =\n        \n          \n            {\n            \n              \n                \n                  x\n                \n                \n                  \n                    if \n                  \n                  x\n                  >\n                  0\n                  ,\n                \n              \n              \n                \n                  0\n                \n                \n                  x\n                  \u2264\n                  0\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle \\operatorname {ReLU} (x)=x^{+}=\\max(0,x)={\\frac {x+|x|}{2}}={\\begin{cases}x&{\\text{if }}x>0,\\\\0&x\\leq 0\\end{cases}}}\n  \n\nwhere \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n is the input to a neuron.", "This is analogous to half-wave rectification in electrical engineering. ReLU is one of the most popular activation functions for artificial neural networks, and finds application in computer vision and speech recognition using deep neural nets and computational neuroscience.", "Recurrent neural networks (RNNs) are a class of artificial neural networks designed for processing sequential data, such as text, speech, and time series, where the order of elements is important. Unlike feedforward neural networks, which process inputs independently, RNNs utilize recurrent connections, where the output of a neuron at one time step is fed back as input to the network at the next time step. This enables RNNs to capture temporal dependencies and patterns within sequences.", "The fundamental building block of RNNs is the recurrent unit, which maintains a hidden state\u2014a form of memory that is updated at each time step based on the current input and the previous hidden state. This feedback mechanism allows the network to learn from past inputs and incorporate that knowledge into its current processing.", "RNNs have been successfully applied to tasks such as unsegmented, connected handwriting recognition, speech recognition, natural language processing, and neural machine translation. However, traditional RNNs suffer from the vanishing gradient problem, which limits their ability to learn long-range dependencies. This issue was addressed by the development of the long short-term memory (LSTM) architecture in 1997, making it the standard RNN variant for handling long-term dependencies.", "Later, Gated Recurrent Units (GRUs) were introduced as a more computationally efficient alternative. In recent years, Transformers, which rely on self-attention mechanisms instead of recurrence, have become the dominant architecture for many sequence-processing tasks, particularly in natural language processing, due to their superior handling of long-range dependencies and greater parallelizability.", "Nevertheless, RNNs remain relevant for applications where computational efficiency, real-time processing, or the inherent sequential nature of data is crucial.", "Retrieval-augmented generation (RAG) is a technique that enables generative artificial intelligence (Gen AI) models to retrieve and incorporate new information. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to supplement information from its pre-existing training data. This allows LLMs to use domain-specific and/or updated information.", "Use cases include providing chatbot access to internal company data or generating responses based on authoritative sources. RAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources.", "According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have led to real-world issues like chatbots inventing policies or lawyers citing nonexistent legal cases. By dynamically retrieving information, RAG enables AI to provide more accurate responses without frequent retraining.", "According to IBM, \"RAG also reduces the need for users to continuously train the model on new data and update its parameters as circumstances evolve. In this way, RAG can lower the computational and financial costs of running LLM-powered chatbots in an enterprise setting.\" Beyond efficiency gains, RAG also allows LLMs to include source references in their responses, enabling users to verify information by reviewing cited documents or original sources.", "This can provide greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance. The term \"retrieval-augmented generation\" (RAG) was first introduced in 2020 by Douwe Kiela, Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, and Sebastian Riedel in their research paper Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, at Meta.", "Runway AI, Inc. (also known as Runway and RunwayML) is an American company headquartered in New York City that specializes in generative artificial intelligence research and technologies. The company is primarily focused on creating products and models for generating videos, images, and various multimedia content. It is most notable for developing the commercial text-to-video and video generative AI models Gen-1, Gen-2, Gen-3 Alpha and Gen-4.", "Runway's tools and AI models have been utilized in films such as Everything Everywhere All At Once, in music videos for artists including A$AP Rocky, Kanye West, Brockhampton, and The Dandy Warhols, and in editing television shows like The Late Show and Top Gear.", "A semantic decomposition is an algorithm that breaks down the meanings of phrases or concepts into less complex concepts. The result of a semantic decomposition is a representation of meaning. This representation can be used for tasks, such as those related to artificial intelligence or machine learning. Semantic decomposition is common in natural language processing applications.", "The basic idea of a semantic decomposition is taken from the learning skills of adult humans, where words are explained using other words. It is based on Meaning-text theory. Meaning-text theory is used as a theoretical linguistic framework to describe the meaning of concepts with other concepts.", "Small object detection is a particular case of object detection where various techniques are employed to detect small objects in digital images and videos. \"Small objects\" are objects having a small pixel footprint in the input image. In areas such as aerial imagery, state-of-the-art object detection techniques under performed because of small objects.", "In machine learning, supervised learning (SL) is a paradigm where a model is trained using input objects (e.g. a vector of predictor variables) and desired output values (also known as a supervisory signal), which are often human-made labels. The training process builds a function that maps new data to expected output values. An optimal scenario will allow for the algorithm to accurately determine output values for unseen instances.", "This requires the learning algorithm to generalize from the training data to unseen situations in a reasonable way (see inductive bias). This statistical quality of an algorithm is measured via a generalization error.", "T5 (Text-to-Text Transfer Transformer) is a series of large language models developed by Google AI introduced in 2019. Like the original Transformer model, T5 models are encoder-decoder Transformers, where the encoder processes the input text, and the decoder generates the output text. T5 models are usually pretrained on a massive dataset of text and code, after which they can perform the text-based tasks that are similar to their pretrained tasks.", "They can also be finetuned to perform other tasks. T5 models have been employed in various applications, including chatbots, machine translation systems, text summarization tools, code generation, and robotics.", "Three-dimensional face recognition (3D face recognition) is a modality of facial recognition methods in which the three-dimensional geometry of the human face is used. It has been shown that 3D face recognition methods can achieve significantly higher accuracy than their 2D counterparts, rivaling fingerprint recognition. 3D face recognition has the potential to achieve better accuracy than its 2D counterpart by measuring geometry of rigid features on the face.", "This avoids such pitfalls of 2D face recognition algorithms as change in lighting, different facial expressions, make-up and head orientation. Another approach is to use the 3D model to improve accuracy of traditional image based recognition by transforming the head into a known view. Additionally, most 3D scanners acquire both a 3D mesh and the corresponding texture.", "This allows combining the output of pure 3D matchers with the more traditional 2D face recognition algorithms, thus yielding better performance (as shown in FRVT 2006). The main technological limitation of 3D face recognition methods is the acquisition of 3D image, which usually requires a range camera. Alternatively, multiple images from different angles from a common camera (e.g. webcam) may be used to create the 3D model with significant post-processing.", "(See 3D data acquisition and object reconstruction.) This is also a reason why 3D face recognition methods have emerged significantly later (in the late 1980s) than 2D methods. Recently commercial solutions have implemented depth perception by projecting a grid onto the face and integrating video capture of it into a high resolution 3D model. This allows for good recognition accuracy with low cost off-the-shelf components.", "3D face recognition is still an active research field, though several vendors offer commercial solutions.", "In digital image processing, thresholding is the simplest method of segmenting images. From a grayscale image, thresholding can be used to create binary images.", "This is a timeline of artificial intelligence, sometimes alternatively called synthetic intelligence.", "The transformer is a deep learning architecture that was developed by researchers at Google and is based on the multi-head attention mechanism, which was proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table.", "At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished. Transformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM).", "Later variations have been widely adopted for training large language models (LLM) on large (language) datasets. Transformers were first developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess.", "It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).", "In computer vision, triangulation refers to the process of determining a point in 3D space given its projections onto two, or more, images. In order to solve this problem it is necessary to know the parameters of the camera projection function from 3D to 2D for the cameras involved, in the simplest case represented by the camera matrices. Triangulation is sometimes also referred to as reconstruction or intersection. The triangulation problem is in principle trivial.", "Since each point in an image corresponds to a line in 3D space, all points on the line in 3D are projected to the point in the image. If a pair of corresponding points in two, or more images, can be found it must be the case that they are the projection of a common 3D point x. The set of lines generated by the image points must intersect at x  (3D point) and the algebraic formulation of the coordinates of x (3D point) can be computed in a variety of ways, as is presented below.", "In practice, however, the coordinates of image points cannot be measured with arbitrary accuracy. Instead, various types of noise, such as geometric noise from lens distortion or interest point detection error, lead to inaccuracies in the measured image coordinates. As a consequence, the lines generated by the corresponding image points do not always intersect in 3D space. The problem, then, is to find a 3D point which optimally fits the measured image points.", "In the literature there are multiple proposals for how to define optimality and how to find the optimal 3D point. Since they are based on different optimality criteria, the various methods produce different estimates of the 3D point x when noise is involved.", "A vector database, vector store or vector search engine is a database that can store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more Approximate Nearest Neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records. Vectors are mathematical representations of data in a high-dimensional space.", "In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the complexity of the data being represented. A vector's position in this space represents its characteristics. Words, phrases, or entire documents, as well as images, audio, and other types of data, can all be vectorized.", "These feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks. The goal is that semantically similar data items receive feature vectors close to each other. Vector databases can be used for similarity search, semantic search, multi-modal search, recommendations engines, large language models (LLMs), object detection,  etc.", "Vector databases are also often used to implement retrieval-augmented generation (RAG), a method to improve domain-specific responses of large language models. The retrieval component of a RAG can be any search system, but is most often implemented as a vector database.", "Text documents describing the domain of interest are collected, and for each document or document section, a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database. Given a user prompt, the feature vector of the prompt is computed, and the database is queried to retrieve the most relevant documents.", "These are then automatically added into the context window of the large language model, and the large language model proceeds to create a response to the prompt given this context.", "Video content analysis or video content analytics (VCA), also known as video analysis or video analytics (VA), is the capability of automatically analyzing video to detect and determine temporal and spatial events. This technical capability is used in a wide range of domains including entertainment, video retrieval and video browsing, health-care, retail, automotive, transport, home automation, flame and smoke detection, safety, and security.", "The algorithms can be implemented as software on general-purpose machines, or as hardware in specialized video processing units. Many different functionalities can be implemented in VCA. Video Motion Detection is one of the simpler forms where motion is detected with regard to a fixed background scene. More advanced functionalities include video tracking and egomotion estimation.", "Based on the internal representation that VCA generates in the machine, it is possible to build other functionalities, such as video summarization, identification, behavior analysis, or other forms of situation awareness. VCA relies on good input video, so it is often combined with video enhancement technologies such as video denoising, image stabilization, unsharp masking, and super-resolution.", "The Viola\u2013Jones object detection framework is a machine learning object detection framework proposed in 2001 by Paul Viola and Michael Jones. It was motivated primarily by the problem of face detection, although it can be adapted to the detection of other object classes. In short, it consists of a sequence of classifiers. Each classifier is a single perceptron with several binary masks (Haar features). To detect faces in an image, a sliding window is computed over the image.", "For each image, the classifiers are applied. If at any point, a classifier outputs \"no face detected\", then the window is considered to contain no face. Otherwise, if all classifiers output \"face detected\", then the window is considered to contain a face. The algorithm is efficient for its time, able to detect faces in 384 by 288 pixel images at 15 frames per second on a conventional 700 MHz Intel Pentium III. It is also robust, achieving high precision and recall.", "While it has lower accuracy than more modern methods such as convolutional neural network, its efficiency and compact size (only around 50k parameters, compared to millions of parameters for typical CNN like DeepFace) means it is still used in cases with limited computational power. For example, in the original paper, they reported that this face detector could run on the Compaq iPAQ at 2 fps (this device has a low power StrongARM without floating point hardware).", "In the study of image processing, a watershed is a transformation defined on a grayscale image. The name refers metaphorically to a geological watershed, or drainage divide, which separates adjacent drainage basins. The watershed transformation treats the image it operates upon like a topographic map, with the brightness of each point representing its height, and finds the lines that run along the tops of ridges. There are different technical definitions of a watershed.", "In graphs, watershed lines may be defined on the nodes, on the edges, or hybrid lines on both nodes and edges. Watersheds may also be defined in the continuous domain. There are also many different algorithms to compute watersheds. Watershed algorithms are used in image processing primarily for object segmentation purposes, that is, for separating different objects in an image. This allows for counting the objects or for further analysis of the separated objects.", "You Only Look Once (YOLO) is a series of real-time object detection systems based on convolutional neural networks. First introduced by Joseph Redmon et al. in 2015, YOLO has undergone several iterations and improvements, becoming one of the most popular object detection frameworks.", "The name \"You Only Look Once\" refers to the fact that the algorithm requires only one forward propagation pass through the neural network to make predictions, unlike previous region proposal-based techniques like R-CNN that require thousands for a single image."], "metadata": [{"source": "A.I._Artificial_Intelligence.txt"}, {"source": "A.I._Artificial_Intelligence.txt"}, {"source": "A.I._Artificial_Intelligence.txt"}, {"source": "A.I._Artificial_Intelligence.txt"}, {"source": "Active_learning_(machine_learning).txt"}, {"source": "Active_learning_(machine_learning).txt"}, {"source": "Active_learning_(machine_learning).txt"}, {"source": "Active_learning_(machine_learning).txt"}, {"source": "Adversarial_machine_learning.txt"}, {"source": "Adversarial_machine_learning.txt"}, {"source": "Affective_computing.txt"}, {"source": "Affective_computing.txt"}, {"source": "Affective_computing.txt"}, {"source": "AI_boom.txt"}, {"source": "AlexNet.txt"}, {"source": "AlexNet.txt"}, {"source": "AlexNet.txt"}, {"source": "Applications_of_artificial_intelligence.txt"}, {"source": "Applications_of_artificial_intelligence.txt"}, {"source": "Artificial_general_intelligence.txt"}, {"source": "Artificial_general_intelligence.txt"}, {"source": "Artificial_general_intelligence.txt"}, {"source": "Artificial_general_intelligence.txt"}, {"source": "Artificial_general_intelligence.txt"}, {"source": "Artificial_general_intelligence.txt"}, {"source": "Artificial_intelligence.txt"}, {"source": "Artificial_intelligence.txt"}, {"source": "Artificial_intelligence.txt"}, {"source": "Artificial_intelligence.txt"}, {"source": "Artificial_intelligence.txt"}, {"source": "Artificial_intelligence.txt"}, {"source": "Artificial_intelligence.txt"}, {"source": "Artificial_intelligence.txt"}, {"source": "Artificial_intelligence_art.txt"}, {"source": "Artificial_intelligence_art.txt"}, {"source": "Artificial_intelligence_art.txt"}, {"source": "Artificial_intelligence_in_video_games.txt"}, {"source": "Artificial_intelligence_in_video_games.txt"}, {"source": "Artificial_intelligence_in_video_games.txt"}, {"source": "Attention_(machine_learning).txt"}, {"source": "Attention_(machine_learning).txt"}, {"source": "Attention_(machine_learning).txt"}, {"source": "BERT_(language_model).txt"}, {"source": "BERT_(language_model).txt"}, {"source": "BERT_(language_model).txt"}, {"source": "ChatGPT.txt"}, {"source": "ChatGPT.txt"}, {"source": "ChatGPT.txt"}, {"source": "ChatGPT.txt"}, {"source": "ChatGPT.txt"}, {"source": "Chinchilla_(language_model).txt"}, {"source": "Chroma_(vector_database).txt"}, {"source": "Claude_(language_model).txt"}, {"source": "Claude_(language_model).txt"}, {"source": "Computer_stereo_vision.txt"}, {"source": "Computer_vision.txt"}, {"source": "Computer_vision.txt"}, {"source": "Computer_vision.txt"}, {"source": "Computer_vision.txt"}, {"source": "Computer_Vision_Annotation_Tool.txt"}, {"source": "Computer_Vision_Annotation_Tool.txt"}, {"source": "Computer_Vision_Annotation_Tool.txt"}, {"source": "Computer_vision_dazzle.txt"}, {"source": "Computer_vision_syndrome.txt"}, {"source": "Convolutional_neural_network.txt"}, {"source": "Convolutional_neural_network.txt"}, {"source": "Convolutional_neural_network.txt"}, {"source": "Convolutional_neural_network.txt"}, {"source": "Convolutional_neural_network.txt"}, {"source": "Convolutional_neural_network.txt"}, {"source": "Convolutional_neural_network.txt"}, {"source": "Convolutional_neural_network.txt"}, {"source": "Deeper_learning.txt"}, {"source": "Deeper_learning.txt"}, {"source": "Deep_learning.txt"}, {"source": "Deep_learning.txt"}, {"source": "Deep_learning.txt"}, {"source": "Deep_learning.txt"}, {"source": "Deep_Learning_(South_Park).txt"}, {"source": "Deep_Learning_(South_Park).txt"}, {"source": "Deep_Learning_Super_Sampling.txt"}, {"source": "Deep_Learning_Super_Sampling.txt"}, {"source": "Deep_reinforcement_learning.txt"}, {"source": "Deep_reinforcement_learning.txt"}, {"source": "Digital_image_processing.txt"}, {"source": "Digital_image_processing.txt"}, {"source": "Digital_image_processing.txt"}, {"source": "Empirical_Methods_in_Natural_Language_Processing.txt"}, {"source": "Empirical_Methods_in_Natural_Language_Processing.txt"}, {"source": "Face_ID.txt"}, {"source": "Face_ID.txt"}, {"source": "Face_ID.txt"}, {"source": "Face_ID.txt"}, {"source": "Face_ID.txt"}, {"source": "Face_ID.txt"}, {"source": "Face_ID.txt"}, {"source": "Face_ID.txt"}, {"source": "Face_perception.txt"}, {"source": "Face_perception.txt"}, {"source": "Face_perception.txt"}, {"source": "Face_Recognition_Grand_Challenge.txt"}, {"source": "Facial_recognition_system.txt"}, {"source": "Facial_recognition_system.txt"}, {"source": "Facial_recognition_system.txt"}, {"source": "Facial_recognition_system.txt"}, {"source": "Facial_recognition_system.txt"}, {"source": "Facial_recognition_system.txt"}, {"source": "Feature_(computer_vision).txt"}, {"source": "Feature_(computer_vision).txt"}, {"source": "Feature_(computer_vision).txt"}, {"source": "Feedforward_neural_network.txt"}, {"source": "Feedforward_neural_network.txt"}, {"source": "Feedforward_neural_network.txt"}, {"source": "Fusiform_face_area.txt"}, {"source": "Gemini_(language_model).txt"}, {"source": "Generative_AI_pornography.txt"}, {"source": "Generative_artificial_intelligence.txt"}, {"source": "Generative_artificial_intelligence.txt"}, {"source": "Generative_artificial_intelligence.txt"}, {"source": "Generative_artificial_intelligence.txt"}, {"source": "Generative_pre-trained_transformer.txt"}, {"source": "Generative_pre-trained_transformer.txt"}, {"source": "Generative_pre-trained_transformer.txt"}, {"source": "Generative_pre-trained_transformer.txt"}, {"source": "Gradient-domain_image_processing.txt"}, {"source": "Graph_neural_network.txt"}, {"source": "Graph_neural_network.txt"}, {"source": "Graph_neural_network.txt"}, {"source": "Graph_neural_network.txt"}, {"source": "Graph_neural_network.txt"}, {"source": "Graph_neural_network.txt"}, {"source": "Hallucination_(artificial_intelligence).txt"}, {"source": "Hallucination_(artificial_intelligence).txt"}, {"source": "Hallucination_(artificial_intelligence).txt"}, {"source": "History_of_artificial_intelligence.txt"}, {"source": "History_of_artificial_intelligence.txt"}, {"source": "History_of_artificial_intelligence.txt"}, {"source": "History_of_artificial_intelligence.txt"}, {"source": "History_of_artificial_intelligence.txt"}, {"source": "History_of_artificial_intelligence.txt"}, {"source": "History_of_artificial_neural_networks.txt"}, {"source": "History_of_artificial_neural_networks.txt"}, {"source": "History_of_artificial_neural_networks.txt"}, {"source": "History_of_natural_language_processing.txt"}, {"source": "Homography_(computer_vision).txt"}, {"source": "Homography_(computer_vision).txt"}, {"source": "Image.txt"}, {"source": "Image.txt"}, {"source": "Image.txt"}, {"source": "Image.txt"}, {"source": "Image_processor.txt"}, {"source": "Image_processor.txt"}, {"source": "Kernel_(image_processing).txt"}, {"source": "LangChain.txt"}, {"source": "Language_model.txt"}, {"source": "Language_model.txt"}, {"source": "Large_language_model.txt"}, {"source": "Large_language_model.txt"}, {"source": "Large_language_models_in_government.txt"}, {"source": "List_of_datasets_for_machine-learning_research.txt"}, {"source": "List_of_datasets_for_machine-learning_research.txt"}, {"source": "List_of_datasets_for_machine-learning_research.txt"}, {"source": "List_of_datasets_in_computer_vision_and_image_processing.txt"}, {"source": "List_of_large_language_models.txt"}, {"source": "Llama_(language_model).txt"}, {"source": "Llama_(language_model).txt"}, {"source": "Llama_(language_model).txt"}, {"source": "Machine_learning.txt"}, {"source": "Machine_learning.txt"}, {"source": "Machine_learning.txt"}, {"source": "Microscope_image_processing.txt"}, {"source": "Moving_object_detection.txt"}, {"source": "Music_and_artificial_intelligence.txt"}, {"source": "Music_and_artificial_intelligence.txt"}, {"source": "Music_and_artificial_intelligence.txt"}, {"source": "Music_and_artificial_intelligence.txt"}, {"source": "Natural-language_user_interface.txt"}, {"source": "Natural-language_user_interface.txt"}, {"source": "Natural_language.txt"}, {"source": "Natural_language_processing.txt"}, {"source": "Natural_language_processing.txt"}, {"source": "Natural_Language_Toolkit.txt"}, {"source": "Natural_Language_Toolkit.txt"}, {"source": "Natural_Language_Toolkit.txt"}, {"source": "NebulaGraph.txt"}, {"source": "Neural_network.txt"}, {"source": "Neural_network.txt"}, {"source": "Neural_network_(biology).txt"}, {"source": "Neural_network_(biology).txt"}, {"source": "Neural_network_(machine_learning).txt"}, {"source": "Neural_network_(machine_learning).txt"}, {"source": "Neural_network_(machine_learning).txt"}, {"source": "Neural_network_(machine_learning).txt"}, {"source": "Normalization_(image_processing).txt"}, {"source": "Normalization_(image_processing).txt"}, {"source": "Normalization_(image_processing).txt"}, {"source": "Normalization_(image_processing).txt"}, {"source": "Normalization_(image_processing).txt"}, {"source": "Normalization_(image_processing).txt"}, {"source": "Normalization_(image_processing).txt"}, {"source": "Normalization_(image_processing).txt"}, {"source": "Normalization_(image_processing).txt"}, {"source": "Object_detection.txt"}, {"source": "OpenAI_o1.txt"}, {"source": "Outline_of_natural_language_processing.txt"}, {"source": "Outline_of_natural_language_processing.txt"}, {"source": "Outline_of_object_recognition.txt"}, {"source": "Outline_of_object_recognition.txt"}, {"source": "Pareidolia.txt"}, {"source": "Pareidolia.txt"}, {"source": "Pareidolia.txt"}, {"source": "Physics-informed_neural_networks.txt"}, {"source": "Physics-informed_neural_networks.txt"}, {"source": "Pose_(computer_vision).txt"}, {"source": "Pose_(computer_vision).txt"}, {"source": "Prompt_engineering.txt"}, {"source": "Prompt_engineering.txt"}, {"source": "Prompt_engineering.txt"}, {"source": "Prosopagnosia.txt"}, {"source": "Prosopagnosia.txt"}, {"source": "Pyramid_(image_processing).txt"}, {"source": "Q-learning.txt"}, {"source": "Q-learning.txt"}, {"source": "Q-learning.txt"}, {"source": "Quantum_machine_learning.txt"}, {"source": "Quantum_machine_learning.txt"}, {"source": "Quantum_machine_learning.txt"}, {"source": "Quantum_machine_learning.txt"}, {"source": "Quantum_machine_learning.txt"}, {"source": "Quantum_natural_language_processing.txt"}, {"source": "Reasoning_language_model.txt"}, {"source": "Rectifier_(neural_networks).txt"}, {"source": "Rectifier_(neural_networks).txt"}, {"source": "Rectifier_(neural_networks).txt"}, {"source": "Recurrent_neural_network.txt"}, {"source": "Recurrent_neural_network.txt"}, {"source": "Recurrent_neural_network.txt"}, {"source": "Recurrent_neural_network.txt"}, {"source": "Recurrent_neural_network.txt"}, {"source": "Retrieval-augmented_generation.txt"}, {"source": "Retrieval-augmented_generation.txt"}, {"source": "Retrieval-augmented_generation.txt"}, {"source": "Retrieval-augmented_generation.txt"}, {"source": "Retrieval-augmented_generation.txt"}, {"source": "Runway_(company).txt"}, {"source": "Runway_(company).txt"}, {"source": "Semantic_decomposition_(natural_language_processing).txt"}, {"source": "Semantic_decomposition_(natural_language_processing).txt"}, {"source": "Small_object_detection.txt"}, {"source": "Supervised_learning.txt"}, {"source": "Supervised_learning.txt"}, {"source": "T5_(language_model).txt"}, {"source": "T5_(language_model).txt"}, {"source": "Three-dimensional_face_recognition.txt"}, {"source": "Three-dimensional_face_recognition.txt"}, {"source": "Three-dimensional_face_recognition.txt"}, {"source": "Three-dimensional_face_recognition.txt"}, {"source": "Three-dimensional_face_recognition.txt"}, {"source": "Thresholding_(image_processing).txt"}, {"source": "Timeline_of_artificial_intelligence.txt"}, {"source": "Transformer_(deep_learning_architecture).txt"}, {"source": "Transformer_(deep_learning_architecture).txt"}, {"source": "Transformer_(deep_learning_architecture).txt"}, {"source": "Transformer_(deep_learning_architecture).txt"}, {"source": "Triangulation_(computer_vision).txt"}, {"source": "Triangulation_(computer_vision).txt"}, {"source": "Triangulation_(computer_vision).txt"}, {"source": "Triangulation_(computer_vision).txt"}, {"source": "Vector_database.txt"}, {"source": "Vector_database.txt"}, {"source": "Vector_database.txt"}, {"source": "Vector_database.txt"}, {"source": "Vector_database.txt"}, {"source": "Vector_database.txt"}, {"source": "Video_content_analysis.txt"}, {"source": "Video_content_analysis.txt"}, {"source": "Video_content_analysis.txt"}, {"source": "Viola\u2013Jones_object_detection_framework.txt"}, {"source": "Viola\u2013Jones_object_detection_framework.txt"}, {"source": "Viola\u2013Jones_object_detection_framework.txt"}, {"source": "Watershed_(image_processing).txt"}, {"source": "Watershed_(image_processing).txt"}, {"source": "You_Only_Look_Once.txt"}, {"source": "You_Only_Look_Once.txt"}]}